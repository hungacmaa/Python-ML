{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f952cae0",
   "metadata": {},
   "source": [
    "Sách 0.2: \n",
    "- ML không thể cải hiện hiệu năng thuật toán hơn khi dữ liệu tăng lên còn DL thì có thể, dữ liệu càng tăng thì hiệu năng của DL càng tốt\n",
    "- Lĩnh vực của DL hiện nay có thể thấy như hệ thống đề suất của các trang thương mại điện tử hoặc mạng xã hội; hệ thống lái tự động trong các dòng xe của tesla; nhận lệnh từ các trợ lý ảo như alexa, siri, google assistant, ...\n",
    "- NEURAL NETWORK ARCHITECTURE (Kiến trúc mạng neurons - Tương tự như mạng nơ ron trong não người)\n",
    "- Cách thức hoạt động của mạng neurons là: dữ liệu được \"lọc\" dần qua các lớp, từ đó mạng tự cải thiện các trọng số để đạt được hiệu suất tốt (hiệu suất được đánh giá bởi các hàm loss, optimizer, ...)\n",
    "- Cách não học: ví dụ khi nhận dạng một khuôn mặt, não cũng sẽ tham chiếu đến một khuôn mặt tiêu chuẩn (khuôn mặt làm mẫu trong não)\n",
    "- Thư viện Theano là thư viện đầu tiên về DL, ngoài ra còn có Torch, PyTorch, MxNet, TensorFlow. Đây là những thư viện mức thấp về DL (Low-Level DL Frameworks)\n",
    "- Thư viện mức cao (High-Level Frameworks) của DL thường dùng là Keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3f9f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "# Getting the data ready\n",
    "# Generate train dummy data for 1000 Students and dummy test for 500\n",
    "#Columns :Age, Hours of Study &Avg Previous test scores\n",
    "np.random.seed(2018) #Setting seed for reproducibility\n",
    "train_data, test_data = np.random.random((1000, 3)), np.random. random((500, 3))\n",
    "#Generate dummy results for 1000 students : Whether Passed (1) or Failed (0)\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "#Defining the model structure with the required layers, # of neurons, activation function and optimizers\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=3, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b743ffef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 0.7075 - accuracy: 0.5070\n",
      "Epoch 2/32\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.4880\n",
      "Epoch 3/32\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.4810\n",
      "Epoch 4/32\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.4860\n",
      "Epoch 5/32\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.4840\n",
      "Epoch 6/32\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.4980\n",
      "Epoch 7/32\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4930\n",
      "Epoch 8/32\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5030\n",
      "Epoch 9/32\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.4960\n",
      "Epoch 10/32\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5050\n",
      "Epoch 11/32\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.4930\n",
      "Epoch 12/32\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4910\n",
      "Epoch 13/32\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.5000\n",
      "Epoch 14/32\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4940\n",
      "Epoch 15/32\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5030\n",
      "Epoch 16/32\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5030\n",
      "Epoch 17/32\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.4920\n",
      "Epoch 18/32\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4960\n",
      "Epoch 19/32\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4870\n",
      "Epoch 20/32\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5060\n",
      "Epoch 21/32\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5080\n",
      "Epoch 22/32\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4990\n",
      "Epoch 23/32\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4920\n",
      "Epoch 24/32\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5010\n",
      "Epoch 25/32\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4970\n",
      "Epoch 26/32\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4940\n",
      "Epoch 27/32\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.4990\n",
      "Epoch 28/32\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5010\n",
      "Epoch 29/32\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5100\n",
      "Epoch 30/32\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5030\n",
      "Epoch 31/32\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5040\n",
      "Epoch 32/32\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5120\n",
      "16/16 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#Train the model and make predictions\n",
    "model.fit(train_data, labels, epochs=32, batch_size=32)\n",
    "#Make predictions from the trained model\n",
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62a0aab",
   "metadata": {},
   "source": [
    "# Các bước xây dựng một mô hình DL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b26d369",
   "metadata": {},
   "source": [
    "- Chuẩn bị dữ liệu\n",
    "- Định nghĩa cấu trúc model\n",
    "- Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb00da6d",
   "metadata": {},
   "source": [
    "# Các khái niệm trong DL\n",
    "- Neuron\n",
    "- Activation Function\n",
    "    + Sigmoid: (0-1)\n",
    "    + Relu\n",
    "- Model\n",
    "- Layers\n",
    "    + Dense layer: là loại layer mà neurons trong đó sẽ được kết nối lại hết với nhau\n",
    "    + Dropout layer: có tác dụng giạm overfitting - cho vào ngay sau lớp muốn dropout\n",
    "    + Trong DL khi đầu vào là hình ảnh thì keras có cung cấp các lớp đặc biệt gọi là convolutional layers (lớp tích chập)\n",
    "    + Tương tự khi xử lý ngôn ngữ có một DNN nâng cao gọi là recurrent neural network (RNN)\n",
    "- Loss Function: Có tác dụng giúp model biết nó có đang học đúng hướng không\n",
    "    + Với bài toán hồi quy: Mean Squared Error (trung bình bình phương), Mean absolute error. Ngoài ra: Mean absolute percentage error (MAPE) và Mean square logarithmic error (MSLE)\n",
    "    + Với bài toán phân loại: Binary cross-entropy, Categorical cross-entropy\n",
    "- Optimizers:\n",
    "    + Batchs: Model sẽ cập nhật trọng số sau khi duyệt qua tất cả các samples trong batch (cái này gọi là 1 interation)\n",
    "    + Epochs: Mỗi lần duyệt số batch sao cho đủ số samples trong tập train thì là 1 epoch\n",
    "    + Stochastic Gradient Descent (SGD): Wn = Wo - lr*loss. Cập nhật mỗi train sample nên để batch = 1\n",
    "    + Adam ??? khó hiểu\n",
    "- Metrics: tác dụng tương tự loss nhưng chỉ chạy trên tập validation\n",
    "    + Binary Accuracy\n",
    "    + Categorical Accuracy\n",
    "    + Sparse Categorical Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eb4933",
   "metadata": {},
   "source": [
    "- Lưu ý: hiệu năng của model thay đổi khá nhỏ sau mỗi batch, epoch -> tăng epoch cho đến khi bão hòa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
