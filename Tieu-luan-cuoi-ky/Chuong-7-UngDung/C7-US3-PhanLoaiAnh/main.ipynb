{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574214a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from random import *\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25323803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4adc48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('fashion-mnist_train.csv', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62ea7159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f78e9f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data_train['label'].values.reshape(1, 60000) # một hàng 60000 cột\n",
    "train = data_train.drop('label', axis=1).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0af4b98",
   "metadata": {},
   "source": [
    "- Nếu chỉ là data_train['label'] thì shape sẽ chỉ là (60000) tuy nhiên chúng ta cần dạng tensor nên cần reshape bằng (1,60000)\n",
    "- Hàm transpose sẽ đổi hàng thành cột và cột thành hàng. Tức là như dữ liệu ban đầu (hàng là bản ghi, cột là thuộc tính, sau khi transpose thì hàng là thuộc tính, cột là bản ghi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f303af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(train / 255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f3e474",
   "metadata": {},
   "source": [
    "# Bắt đầu thử với 1 hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481bec33",
   "metadata": {},
   "source": [
    "Hình ảnh của mạng - Sách 0.3B trang 106/425"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be7bd70",
   "metadata": {},
   "source": [
    "- Hàm softmax sẽ biến một vector k chiều thành 1 vector k chiều có tổng bằng 1 và các giá trị thuộc khoảng (0;1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e15fdf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((5,2))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "455c47d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 60000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32821d74",
   "metadata": {},
   "source": [
    "Mã hóa one-hot endcoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "263b1843",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ = np.zeros((60000, 10))\n",
    "labels_[np.arange(60000), labels] = 1\n",
    "labels_ = labels_.transpose()\n",
    "labels_ = np.array(labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad129c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10, 60000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_\n",
    "labels_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d188c00b",
   "metadata": {},
   "source": [
    "# Bắt đầu tạo model với tensorflow từ đây"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e83364a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 784\n",
    "tf.reset_default_graph()\n",
    "# Number of neurons in the layers\n",
    "n1 = 5 # Number of neurons in layer 1\n",
    "n2 = 10 # Number of neurons in output layer\n",
    "cost_history = np.empty(shape=[1], dtype = float)\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [10, None])\n",
    "W1 = tf.Variable(tf.truncated_normal([n1, n_dim], stddev=.1))\n",
    "b1 = tf.Variable(tf.zeros([n1,1]))\n",
    "W2 = tf.Variable(tf.truncated_normal([n2, n1], stddev=.1))\n",
    "b2 = tf.Variable(tf.zeros([n2,1]))\n",
    "# Let's build our network...\n",
    "Z1 = tf.nn.relu(tf.matmul(W1, X) + b1)\n",
    "Z2 = tf.nn.relu(tf.matmul(W2, Z1) + b2)\n",
    "y_ = tf.nn.softmax(Z2,0)\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8632f483",
   "metadata": {},
   "source": [
    "- Giải thích các hàm:\n",
    "- tf.truncated_normal([n1, n_dim], stddev=.1): sinh ngẫu nhiên\n",
    "- tf.matmul(W1, X): tích vô hướng\n",
    "- tf.reduce_mean: tính giá trị trung bình của tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5943b970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09003057],\n",
       "       [0.24472848],\n",
       "       [0.66524094]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = tf.constant([[1.], [2.], [3.]])\n",
    "sm = tf.nn.softmax(l, 0)\n",
    "s1 = tf.Session()\n",
    "s1.run(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5317b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "training_epochs = 800\n",
    "cost_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e0c4a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train\n",
    "labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5631832b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.32529938\n",
      "Reached epoch 20 cost J = 0.30868238\n",
      "Reached epoch 40 cost J = 0.28770435\n",
      "Reached epoch 60 cost J = 0.26667133\n",
      "Reached epoch 80 cost J = 0.24788605\n",
      "Reached epoch 100 cost J = 0.23176329\n",
      "Reached epoch 120 cost J = 0.21906896\n",
      "Reached epoch 140 cost J = 0.21029377\n",
      "Reached epoch 160 cost J = 0.20430641\n",
      "Reached epoch 180 cost J = 0.19967963\n",
      "Reached epoch 200 cost J = 0.19572495\n",
      "Reached epoch 220 cost J = 0.19213395\n",
      "Reached epoch 240 cost J = 0.18879402\n",
      "Reached epoch 260 cost J = 0.18564856\n",
      "Reached epoch 280 cost J = 0.1826727\n",
      "Reached epoch 300 cost J = 0.17985298\n",
      "Reached epoch 320 cost J = 0.17719509\n",
      "Reached epoch 340 cost J = 0.1747138\n",
      "Reached epoch 360 cost J = 0.17241956\n",
      "Reached epoch 380 cost J = 0.17032586\n",
      "Reached epoch 400 cost J = 0.1684272\n",
      "Reached epoch 420 cost J = 0.16670969\n",
      "Reached epoch 440 cost J = 0.16515733\n",
      "Reached epoch 460 cost J = 0.16375083\n",
      "Reached epoch 480 cost J = 0.16247234\n",
      "Reached epoch 500 cost J = 0.16130571\n",
      "Reached epoch 520 cost J = 0.16023746\n",
      "Reached epoch 540 cost J = 0.15925443\n",
      "Reached epoch 560 cost J = 0.15835015\n",
      "Reached epoch 580 cost J = 0.15751971\n",
      "Reached epoch 600 cost J = 0.15675262\n",
      "Reached epoch 620 cost J = 0.1560398\n",
      "Reached epoch 640 cost J = 0.1553772\n",
      "Reached epoch 660 cost J = 0.1547581\n",
      "Reached epoch 680 cost J = 0.15417723\n",
      "Reached epoch 700 cost J = 0.1536275\n",
      "Reached epoch 720 cost J = 0.15310429\n",
      "Reached epoch 740 cost J = 0.1525949\n",
      "Reached epoch 760 cost J = 0.15206115\n",
      "Reached epoch 780 cost J = 0.15140958\n",
      "Reached epoch 800 cost J = 0.14970912\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs+1):\n",
    "    sess.run(optimizer, feed_dict = {X: train, Y: labels_, learning_rate: 0.001})\n",
    "    cost_ = sess.run(cost, feed_dict={ X:train, Y: labels_, learning_rate: 0.001})\n",
    "    if cost_ is np.nan:\n",
    "        print(\"????\")\n",
    "        break\n",
    "    else:\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "        if (epoch % 20 == 0):\n",
    "            print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "01213ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_2:0' shape=(10, ?) dtype=float32>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e014e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.66643333\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\")) # hàm cast để đổi kiểu của một tensor\n",
    "print (\"Accuracy:\", accuracy.eval({X: train, Y: labels_, learning_rate:0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b3bd522",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dev = pd.read_csv('fashion-mnist_test.csv', header = 0)\n",
    "labels_dev = data_dev['label'].values.reshape(1, 10000)\n",
    "labels_dev_ = np.zeros((10000, 10))\n",
    "labels_dev_[np.arange(10000), labels_dev] = 1\n",
    "labels_dev_ = labels_dev_.transpose()\n",
    "dev = data_dev.drop('label', axis=1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f66d838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6466\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: dev, Y: labels_dev_, learning_rate:0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f639b698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_3:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7f7140",
   "metadata": {},
   "source": [
    "# Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d35222a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.31843516\n",
      "Reached epoch 50 cost J = 0.12358896\n",
      "Reached epoch 100 cost J = 0.0964246\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "training_epochs = 100\n",
    "cost_history = []\n",
    "for epoch in range(training_epochs+1):\n",
    "    sess.run(optimizer, feed_dict = {X: train, Y: labels_, learning_rate:0.01})\n",
    "    cost_ = sess.run(cost, feed_dict={ X:train, Y: labels_, learning_rate:0.01})\n",
    "    cost_history = np.append(cost_history, cost_)\n",
    "    if (epoch % 50 == 0):\n",
    "        print(\"Reached epoch\",epoch,\"cost J =\", cost_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38647979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Equal:0' shape=(?,) dtype=bool>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0b35b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80653334\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: train, Y: labels_, learning_rate:0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "17804baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1.]\n",
      "0.6666667\n"
     ]
    }
   ],
   "source": [
    "b = tf.equal([1.,2.,4.], [0,2.,4.])\n",
    "a = tf.cast(b, \"float\")\n",
    "acc = tf.reduce_mean(a)\n",
    "print(tf.Session().run(a))\n",
    "print(tf.Session().run(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36027bd4",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c0af39b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 60000)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10, 60000)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n",
    "labels_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cc1c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.21477713\n",
      "Reached epoch 1 cost J = 0.20312396\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "cost_history = []\n",
    "for epoch in range(2+1):\n",
    "    for i in range(0, train.shape[1], 1):\n",
    "        X_train_mini = train[:,i:i + 1]\n",
    "        y_train_mini = labels_[:,i:i + 1]\n",
    "        sess.run(optimizer, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: 0.0001})\n",
    "        cost_ = sess.run(cost, feed_dict={ X:train, Y: labels_, learning_rate: 0.0001})\n",
    "    cost_history = np.append(cost_history, cost_)\n",
    "    print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f8b223",
   "metadata": {},
   "source": [
    "Chạy quá lâu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1016991c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.20953572\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [66]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     y_train_mini \u001b[38;5;241m=\u001b[39m labels_[:,i:i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m50\u001b[39m]\n\u001b[0;32m      8\u001b[0m     sess\u001b[38;5;241m.\u001b[39mrun(optimizer, feed_dict \u001b[38;5;241m=\u001b[39m {X: X_train_mini, Y: y_train_mini, learning_rate: \u001b[38;5;241m0.001\u001b[39m})\n\u001b[1;32m----> 9\u001b[0m     cost_ \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m:\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m cost_history \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(cost_history, cost_)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 968\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    970\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m    971\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[1;32m-> 1191\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1371\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m   1377\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1379\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1380\u001b[0m     message \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_text(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1361\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[0;32m   1359\u001b[0m   \u001b[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[0;32m   1360\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[1;32m-> 1361\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1362\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1454\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1453\u001b[0m                         run_metadata):\n\u001b[1;32m-> 1454\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1456\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "cost_history = []\n",
    "for epoch in range(100+1):\n",
    "    for i in range(0, train.shape[1], 50):\n",
    "        X_train_mini = train[:,i:i + 50]\n",
    "        y_train_mini = labels_[:,i:i + 50]\n",
    "        sess.run(optimizer, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: 0.001})\n",
    "        cost_ = sess.run(cost, feed_dict={ X:train, Y: labels_, learning_rate: 0.001})\n",
    "    cost_history = np.append(cost_history, cost_)\n",
    "    if (epoch % 50 == 0):\n",
    "        print(\"Reached epoch\",epoch,\"cost J =\", cost_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2e45421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(minibatch_size, training_epochs, features, classes, logging_step = 100, learning_r = 0.001):\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "            sess.run(optimizer, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "            cost_ = sess.run(cost, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "            cost_history = np.append(cost_history, cost_)\n",
    "        if (epoch % logging_step == 0):\n",
    "            print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "    return sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b378b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_layer (X, n, activation):\n",
    "    ndim = int(X.shape[0])\n",
    "    stddev = 2 / np.sqrt(ndim)\n",
    "    initialization = tf.truncated_normal((n, ndim), stddev = stddev)\n",
    "    W = tf.Variable(init)\n",
    "    b = tf.Variable(tf.zeros([n,1]))\n",
    "    Z = tf.matmul(W,X)+b\n",
    "    return activation(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82de93bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert Operation 'init' to Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m Y \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mplaceholder(tf\u001b[38;5;241m.\u001b[39mfloat32, [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m])\n\u001b[0;32m      7\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mplaceholder(tf\u001b[38;5;241m.\u001b[39mfloat32, shape\u001b[38;5;241m=\u001b[39m())\n\u001b[1;32m----> 8\u001b[0m hidden1 \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_layer\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m hidden2 \u001b[38;5;241m=\u001b[39m create_layer (hidden1, n2, activation \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mrelu)\n\u001b[0;32m     10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m create_layer (hidden2, n3, activation \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39midentity)\n",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36mcreate_layer\u001b[1;34m(X, n, activation)\u001b[0m\n\u001b[0;32m      3\u001b[0m stddev \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(ndim)\n\u001b[0;32m      4\u001b[0m initialization \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtruncated_normal((n, ndim), stddev \u001b[38;5;241m=\u001b[39m stddev)\n\u001b[1;32m----> 5\u001b[0m W \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m b \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mVariable(tf\u001b[38;5;241m.\u001b[39mzeros([n,\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m      7\u001b[0m Z \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmatmul(W,X)\u001b[38;5;241m+\u001b[39mb\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2509\u001b[0m, in \u001b[0;36mOperation.__tf_tensor__\u001b[1;34m(self, dtype, name)\u001b[0m\n\u001b[0;32m   2507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2508\u001b[0m   \u001b[38;5;124;03m\"\"\"Raises a helpful error.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2509\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt convert Operation \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert Operation 'init' to Tensor"
     ]
    }
   ],
   "source": [
    "n_dim = 784\n",
    "n1 = 300\n",
    "n2 = 300\n",
    "n_outputs = 10\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [10, None])\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "hidden1 = create_layer (X, n1, activation = tf.nn.relu)\n",
    "hidden2 = create_layer (hidden1, n2, activation = tf.nn.relu)\n",
    "outputs = create_layer (hidden2, n3, activation = tf.identity)\n",
    "y_ = tf.nn.softmax(outputs)\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "def model(minibatch_size, training_epochs, features, classes, logging_step = 100, learning_r = 0.001):\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "            sess.run(optimizer, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(cost, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "    if (epoch % logging_step == 0):\n",
    "        print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "    return sess, cost_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
